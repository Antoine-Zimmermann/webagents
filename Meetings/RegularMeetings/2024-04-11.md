
# WebAgents CG: Regular Meeting (Apr. 11, 2024)

## Agenda
   * Introduction
       * Introduction of new participants (if any)
       * Review minutes from the previous meeting
       * General CG updates
   * Review of Task Forces
       * Manageable Affordances Task Force
       * Use Cases Task Force
   * Open discussion
       * Requirements for manageable affordances
       * How to evaluate use cases?
       * Timeline for the first CG report on use cases
       * Engagement

## Participants
   * Patrick Hochstenbach
   * Wout Slabbinck
   * Rem Collier
   * Andrei Ciortea
   * Danai Vachtsevanou
   * Pierre-Antoine Champin
   * Julian Padget
   * Stephen Cranefield
   * Jean-Paul Calbimonte
   * Samuele Burattini
   * Luis Gustavo Nardin

**Scribe**: Rem / Andrei

## Meeting Notes

Notes from last meeting at: [https://github.com/w3c-cg/webagents/blob/main/Meetings/RegularMeetings/2024-03-25.md](https://github.com/w3c-cg/webagents/blob/main/Meetings/RegularMeetings/2024-03-25.md)

AC: Reviewing the tools used for meetings - github repository + framapad.

AC: Wiki page for regular meetings includes link to google form to propose content for the next meeting.

AC: Reviewing previous meeting - discusses requirements for MA and first CG report.

AC: We have the template for the CG report - tooling is ongoing.

### Requirements for manageable affordances

AC: Currently working on eliciting requirements for MA.

#### Mangeable affordances in ML pipelines

RC: Last meeting together with Ege we looked at requirements for the manageable actions in ML pipelines scenario: [https://github.com/w3c-cg/webagents/issues/24](https://github.com/w3c-cg/webagents/issues/24)

RC: The target is an ML pipeline. The life cycle of the ML pipeline is a directed multi-graph, decisions might be needed in specific states to transition to the next state. The agents are monitoring the execution of the piepline and can take decisions to improve the pipeline at run time based on the observations they have.

RC: Agents could also propose alternative pieplines. We can have semantic descriptions of the different tasks to be performed and descriptions of the pipelines. Agents can choose one over another pipeline based on the characteristics of the data that comes in.

RC: Each orchestration tool has a specific interface, there isn't a standard interface to interact with the tool. In the beginning you need to provide the input data, which becomes the starting point for the execution of the pipeline.

RC: for the communication, REST APIs potentially wrapped in SDKs. JSON as representation formats.

PA: one question about the REST API and not using Linked Data: What's the obstacle of designing a context that would make it Linked Data for free? As soon as you have a well defined JSON format, it should not be too hard to make it Linked Data for those who see the benefits of RDF.

RC: We don't have control over the tools, e.g. Argo or Airflow. No consistency around it. We are building adapters at UCD.

PA: An under-estimated scenario is that the context is provided off-band, not necessarily embedded in the JSON itself. You are free to apply the context. This brings benefits precisely if the APIs are heterogeneous.

AC: +1, adding semantic descriptions on top of JSON-based REST APIs would also open the door for describing affordances. There are also approaches for lifting and lowering heterogeneous data formats to RDF, e.g. the RDF Mapping Language (RML): [https://rml.io/specs/rml/](https://rml.io/specs/rml/) (managed by the KG Construction CG: [https://www.w3.org/community/kg-construct/)](https://www.w3.org/community/kg-construct/))

PA: There are discussions for creating a WG around RML.

#### Manageable affordances in manufacturing environments

DV: Presents requirements for: [https://github.com/w3c-cg/webagents/issues/27](https://github.com/w3c-cg/webagents/issues/27)

DV: The target is an action execution. The life cycle is composed of several states: Ready, Running, Paused, Terminated with success, Terminated with failure. (DV shows a diagram)

DV: We have multiple affordances in the various states of the action execution. The affordance to start the action execution invokes the action. We also have affordances for pausing/resuming. Then we have affordances for observing the execution: the progress, if the affordances was terminated with success/failure, if the action execution is contextually relevant and appropriate.

DV: Some affordances are not provided by the device itself, they are provided by other devices. Ex: the affordance of observing the completion of the action via a camera feed. An affordance for observing if the human comes too close to the robotic arm via a camera feed.

DV: In summary, we have 6 affordances in total. The first one starts the action execution. The metadata of the first affordance should link to metadata of remaining affordances. The affordances map to transitions in the life cycle.

DV: We use HTTP APIs for exploiting all affordances. We use RDF representation formats â€” so far either W3C WoT TDs or hMAS Resource Profiles.

SC: You have a model of the state machine and a layer of affordances above the state machine. Then there are affordances for observing completing with failure and completed with success. Why not have generic affordances for observing the states?

DV/AC: The observation affordances are generic, but depend on the life cycle. Here we have 3 generic affordances that focus on various aspects of the action execution: if the action execution was completed, if the outcome of the action was the one that was expected, if the execution context held.

### Use Cases TF

RC: We are aiming for a CG report on use cases in time for TPAC 2024.

SC: This use case was proposed by TBL in the Semantic Web paper: [https://github.com/w3c-cg/webagents/issues/36](https://github.com/w3c-cg/webagents/issues/36)

SC: The scenario seems very representative for agents on the Web.

SB: We have a use case here on [https://github.com/w3c-cg/webagents/issues/41](https://github.com/w3c-cg/webagents/issues/41)

SB: This is more of a scenario than a use case, but can be expanded if we want to build a use case around it.

SB: We need agents because they need to crawl the data and make choices at run time. The main idea behind this usecase is that we have to coordinate a task with entities with different capabilities and ways to communicate that must be discovered at runtime (as new entities can come and go over dynamically) The goal is to have something very simple and to start playing around going towards a testbed.

RC: Please everyone try to contribute to this TF. We are aiming to do a CG report for TPAC 2024. This would be nice because the need for use cases was raised at the last TPAC.
